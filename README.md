<<<<<<< HEAD
# Object Detection for Intruder Alert

![Workflow](https://img.shields.io/badge/Workflow-YOLOv8-blue) ![License](https://img.shields.io/badge/License-MIT-green)

> **Real-time** detection of unauthorized intruders in restricted zones using YOLOv8 and OpenCV, with automatic alerts and logging.
=======
**Object Detection Project: PhÃ¡t hiá»‡n ngÆ°á»i xÃ¢m nháº­p vÃ¹ng cáº¥m thá»i gian thá»±c**

**MÃ´ táº£**

**Dá»± Ã¡n nÃ y sá»­ dá»¥ng YOLOv8 vÃ  OpenCV Ä‘á»ƒ phÃ¡t hiá»‡n ngÆ°á»i xÃ¢m nháº­p vÃ o khu vá»±c cáº¥m trong video vÃ  webcam theo thá»i gian thá»±c, Ä‘á»“ng thá»i cáº£nh bÃ¡o vÃ  ghi log vi pháº¡m.**
**Cáº¥u trÃºc thÆ° má»¥c**
>>>>>>> 2abce3a95a493c3b3b84cf388ec6bac8ed0160f2

---

## ğŸ” Features

- **Real-time inference** on video files or webcam stream
- **Customizable restricted zone** via polygon coordinates
- **Automated dataset preparation**: 80/20 train-val split & `data.yaml` generation
- **Configurable training** with data augmentation and hyperparameters
- **Audio and visual alerts** when intruder detected
- **Comprehensive logging**: CSV logs and snapshot images saved to `logs/`
- **Modular structure** for easy maintenance and extension

---

## ğŸ“‚ Project Structure

```
your-project/
â”œâ”€â”€ models/             # Trained weights (best.pt)
â”œâ”€â”€ data/               # Raw data & prepared datasetâ”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ images/     # images/train + images/val
â”‚       â””â”€â”€ labels/     # labels/train + labels/val
â”œâ”€â”€ src/                # Source code modules
â”‚   â”œâ”€â”€ config.py       # Paths and hyperparameters
â”‚   â”œâ”€â”€ utils.py        # Dataset prep & YAML generation
â”‚   â””â”€â”€ infer.py        # Inference & alert logic
â”œâ”€â”€ logs/               # CSV logs and snapshots
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md           # Project guide
â””â”€â”€ .gitignore
```

<<<<<<< HEAD
---

## ğŸš€ Getting Started

### 1. Prerequisites

- Python 3.7+
- Git
- (Optional) [Virtualenv](https://docs.python.org/3/library/venv.html)

### 2. Installation

```bash
# Clone repository
git clone https://github.com/AndreeD05/object-detection-project.git
cd object-detection-project

# (Optional) Create & activate virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/macOS
\.venv\Scripts\activate   # Windows

# Install dependencies
=======
**YÃªu cáº§u:**
Python 3.7+
Virtual environment (venv) khuyáº¿n khÃ­ch
CÃ¡c thÆ° viá»‡n: ultralytics, opencv-python, numpy, playsound


**CÃ i Ä‘áº·t**
**1.Táº¡o vÃ  kÃ­ch hoáº¡t virtual environment (tÃ¹y chá»n nhÆ°ng khuyáº¿n khÃ­ch):**
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
.\.venv\Scripts\activate  # Windows

**2.CÃ i dependencies:**
>>>>>>> 2abce3a95a493c3b3b84cf388ec6bac8ed0160f2
pip install --upgrade pip
pip install -r requirements.txt
```

<<<<<<< HEAD
---

## ğŸ—‚ Dataset Preparation

1. Place raw images in `data/dataset/images/` and corresponding `.txt` labels in `data/dataset/labels/`.
2. Run dataset prep script to split and generate `data.yaml`:
   ```bash
   python -c "from src.utils import prepare_dataset; prepare_dataset()"
   ```
3. Confirm structure:
   ```text
   data/dataset/
   â”œâ”€â”€ images/train
   â”œâ”€â”€ images/val
   â”œâ”€â”€ labels/train
   â””â”€â”€ labels/val
   ```

---

## ğŸ‹ï¸â€â™‚ï¸ Training

Train with YOLOv8:

```bash
python -c "from ultralytics import YOLO; model = YOLO('yolov8n.pt'); model.train(   data='data/dataset/data.yaml',   epochs=30,   batch=16,   imgsz=640,   project='models',   name='custom_train',   exist_ok=True )"
```

- Best weights saved at `models/custom_train/weights/best.pt`.

---
=======
**Chuáº©n bá»‹ dataset**

1.Äáº·t toÃ n bá»™ áº£nh gá»‘c vÃ o data/dataset/images/ vÃ  nhÃ£n .txt vÃ o data/dataset/labels/.
2.Cháº¡y hÃ m prepare_dataset() trong src/utils.py Ä‘á»ƒ tá»± Ä‘á»™ng chia 80% train, 20% val vÃ  sinh file data.yaml:
**python -c "from src.utils import prepare_dataset; prepare_dataset()"**

**Huáº¥n luyá»‡n model**
Cháº¡y lá»‡nh sau Ä‘á»ƒ train báº±ng YOLOv8:
python -c "from ultralytics import YOLO; model=YOLO('yolov8n.pt'); model.train(data='data/dataset/data.yaml', epochs=30, imgsz=640, batch=16, project='models', name='custom_train', exist_ok=True)"

_Káº¿t quáº£ weights best.pt sáº½ náº±m trong runs/detect/custom_train/weights/, báº¡n nÃªn copy vá» thÆ° má»¥c models/._

**Inference & Cáº£nh bÃ¡o**
DÃ¹ng script src/infer.py Ä‘á»ƒ phÃ¡t hiá»‡n trÃªn video hoáº·c webcam:
python src/infer.py --video path/to/input.mp4 --out path/to/output.mp4

_Káº¿t quáº£ video cÃ³ bounding box vÃ  polygon vÃ¹ng cáº¥m sáº½ Ä‘Æ°á»£c lÆ°u táº¡i output.mp4._

**# Video file**
python src/infer.py --video data/test_video.mp4 --out logs/output.mp4

**# Hoáº·c real-time tá»« webcam**
python src/infer.py --video 0 --out logs/webcam_output.mp4
CÃ¡c cáº£nh bÃ¡o, log vi pháº¡m sáº½ Ä‘Æ°á»£c ghi trong thÆ° má»¥c logs/.
>>>>>>> 2abce3a95a493c3b3b84cf388ec6bac8ed0160f2

## ğŸ¥ Inference & Alerts

<<<<<<< HEAD
Run detection on a video or webcam:

```bash
python src/infer.py   --video path/to/input.mp4   --out logs/output.mp4
```

For webcam (default camera):

```bash
python src/infer.py --video 0 --out logs/webcam.mp4
```

- Alerts logged in `logs/` with snapshots and CSV.

---

## âš™ï¸ Configuration

Adjust parameters in `src/config.py`:

- `POLYGON_POINTS`: Coordinates of restricted zone polygon
- `DATA_ROOT`, `EPOCHS`, `BATCH_SIZE`, `IMG_SIZE`, `LEARNING_RATE`, etc.

---

## ğŸ› ï¸ Extending the Project

- Integrate Telegram/Zalo notifications
- Convert model to ONNX/TensorRT for edge deployment
- Wrap inference in a REST API (FastAPI/Flask)

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
=======
**Tinh chá»‰nh & Má»Ÿ rá»™ng**
Thay Ä‘á»•i tá»a Ä‘á»™ vÃ¹ng cáº¥m trong src/config.py.
Chuyá»ƒn sang real-time webcam: --video 0.
TÃ­ch há»£p cáº£nh bÃ¡o Ã¢m thanh, Telegram/Zalo thÃ´ng qua hÃ m trong utils.py

>>>>>>> 2abce3a95a493c3b3b84cf388ec6bac8ed0160f2
